Dieses Repository widmet sich der Erforschung und Analyse der Entwicklung von Musik Ã¼ber verschiedene Zeitperioden. Ziel des Projekts ist es, Muster, Trends und EinflÃ¼sse in der musikalischen Entwicklung zu untersuchen. Die Daten kÃ¶nnen unter folgenden Link eingesehen werden: https://portal.dnb.de/opac.htm?method=showShortList&currentPosition=17&currentResultId=cod%3Dnt%26any%26onlinefree%26scores

Analyse-Pipeline der Deutschen Nationalbibliothek (DNB)

ğŸ”§ Ãœbersicht

Diese Analyse-Pipeline dient dazu, Daten aus der Deutschen Nationalbibliothek (DNB) effizient zu verarbeiten. Sie umfasst:

Automatisiertes Herunterladen von PDFs von der DNB-Webseite.

Textextraktion (direkt oder mittels OCR) aus den PDFs.

Textanalyse und Visualisierung der Ergebnisse.

ğŸ”„ Ablauf der Pipeline

1. PDF-Downloader

Datei: 1_dnb_pdf_downloader.ipynb

Funktion:
Automatisches Herunterladen von PDFs von der Webseite der DNB.

Details:

Die Webseite wird mit Selenium, einer Automatisierungssoftware, navigiert.

Das Programm klickt auf Download-Links und speichert die PDFs lokal.

Download-BeschrÃ¤nkung: StandardmÃ¤ÃŸig werden die ersten 100 PDFs heruntergeladen, um Speicherplatz zu sparen.

Voraussetzungen:

Selenium WebDriver mit Google Chrome.

Download-Verzeichnis: Standardordner ist pdf.

2. PDF-Leser: Textextraktion und OCR

Datei: 2_pdf_reader_base_code.ipynb

Funktion:
Extrahiert Texte und Bilder aus den heruntergeladenen PDFs.

Ablauf:

Direkte Textextraktion:
Wenn der Text digital im PDF enthalten ist, wird er direkt ausgelesen.

Texterkennung (OCR):
Wenn der Text nicht lesbar ist (z. B. bei eingescannten Dokumenten), wird OCR (Optical Character Recognition) verwendet.

Technologien:

PyMuPDF (Fitz): FÃ¼r direkte Textextraktion.

Pytesseract: FÃ¼r OCR auf Bildern.

EasyOCR: Eine genauere OCR-Alternative (ressourcenintensiv).

3. Textanalyse und Visualisierung

Datei: 3_pdf_analyse.ipynb

Funktion:
Analysiert die extrahierten Texte und erstellt eine Wortwolke, um die hÃ¤ufigsten Begriffe zu visualisieren.

Ablauf:

Entfernt irrelevante WÃ¶rter (wie â€derâ€œ, â€undâ€œ) mithilfe einer Liste deutscher StopwÃ¶rter.

Erstellt aus dem bereinigten Text eine Wortwolke mit hÃ¤ufigen Begriffen.

Technologien:

WordCloud: Zur Visualisierung.

Matplotlib: Zur Darstellung der Wortwolke.

NLTK: FÃ¼r die StopwÃ¶rterliste.

ğŸš€ Wie starte ich die Pipeline?

Voraussetzungen

Python 3.9 oder hÃ¶her

Installierte Python-Bibliotheken:

selenium

webdriver-manager

requests

fitz (PyMuPDF)

pytesseract

easyocr

nltk

matplotlib

wordcloud

Tesseract OCR:

Installieren Sie Tesseract von der offiziellen Webseite: https://github.com/tesseract-ocr/tesseract.

Stellen Sie sicher, dass der Pfad zu Tesseract in der Datei korrekt angegeben ist.

Anleitung

Klonen Sie dieses Repository:

git clone <repository-url>

Installieren Sie die AbhÃ¤ngigkeiten:

pip install -r requirements.txt

FÃ¼hren Sie die Dateien in der folgenden Reihenfolge aus:

1_dnb_pdf_downloader.ipynb â” LÃ¤dt die PDFs herunter.

2_pdf_reader_base_code.ipynb â” Extrahiert Texte und Bilder.

3_pdf_analyse.ipynb â” Analysiert Texte und erstellt eine Wortwolke.

ğŸ” Wichtige Hinweise

Speicherplatz:
Das komplette PDF-Set kann sehr groÃŸ sein (bis zu 174 GB). Laden Sie nur so viele Dateien herunter, wie Sie benÃ¶tigen.

Performance:
Die OCR-Erkennung (insbesondere EasyOCR) ist ressourcenintensiv. FÃ¼hren Sie das Skript auf einem leistungsfÃ¤higen Rechner aus.

Datenquellen:
Die verwendeten PDFs stammen von der Webseite der Deutschen Nationalbibliothek und unterliegen deren Nutzungsbedingungen.

ğŸ“Š Beispiel: Ergebnis der Wortwolke

Nach der Analyse sehen Sie eine grafische Darstellung der hÃ¤ufigsten Begriffe in den PDF-Inhalten:



ğŸ› ï¸ Support

Wenn Sie Fragen oder Probleme haben, melden Sie sich bei uns Ã¼ber das Issue-Tracking-System oder per E-Mail.

Viel Erfolg bei der Analyse!
